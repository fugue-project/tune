{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  },
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Non-Iterative Optimizers\n",
    "\n",
    "AKA Level 2 optimizers, are unified 3rd party solutions for random expressions. Look at this space:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tune import Space, Grid, Rand\n",
    "\n",
    "space = Space(a=Grid(1,2), b=Rand(0,1))\n",
    "list(space)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': Rand(low=0, high=1, q=None, log=False, include_high=True)},\n",
       " {'a': 2, 'b': Rand(low=0, high=1, q=None, log=False, include_high=True)}]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Grid` is for level 1 optimization, all level 1 parameters will be converted to static values before execution. And level 2 parameters will be optimized during runtime using level 2 optimizers. So for the above example, if we have a Spark cluster and Hyperopt, then we can use Hyperot to search for the best `b` on each of the 2 configurations. And the 2 jobs are parallelized by Spark."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tune import noniterative_objective, Trial\n",
    "\n",
    "@noniterative_objective\n",
    "def objective(a ,b) -> float:\n",
    "    return a**2 + b**2\n",
    "\n",
    "trial = Trial(\"dummy\", params=list(space)[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Use Directly\n",
    "\n",
    "Notice normally you don't use them directly, instead you should use them through top level APIs. This is just to demo how they work.\n",
    "\n",
    "### Hyperopt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tune_hyperopt import HyperoptLocalOptimizer\n",
    "\n",
    "hyperopt_optimizer = HyperoptLocalOptimizer(max_iter=200, seed=0)\n",
    "report = hyperopt_optimizer.run(objective, trial)\n",
    "\n",
    "print(report.sort_metric, report)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000001665414 {'trial': {'trial_id': 'dummy', 'params': {'a': 1, 'b': 1.2905089873156781e-05}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000001665414, 'params': {'a': 1, 'b': 1.2905089873156781e-05}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000001665414, 'log_time': datetime.datetime(2021, 10, 6, 23, 30, 51, 970344)}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optuna"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from tune_optuna import OptunaLocalOptimizer\n",
    "import optuna\n",
    "\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "optuna_optimizer = OptunaLocalOptimizer(max_iter=200)\n",
    "report = optuna_optimizer.run(objective, trial)\n",
    "\n",
    "print(report.sort_metric, report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000003655019 {'trial': {'trial_id': 'dummy', 'params': {'a': 1, 'b': 1.9118105424729645e-05}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000003655019, 'params': {'a': 1, 'b': 1.9118105424729645e-05}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000003655019, 'log_time': datetime.datetime(2021, 10, 6, 23, 31, 26, 6566)}\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you see, we have unified the interfaces for using these frameworks. In addition, we also unified the semantic of the random expressions, so the random sampling behavior will be highly consistent on different 3rd party solutions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Top Level API\n",
    "\n",
    "In the following example, we directly use the entire `space` where you can mix grid search, random search and Bayesian Optimization."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from tune import suggest_for_noniterative_objective\n",
    "\n",
    "report = suggest_for_noniterative_objective(\n",
    "    objective, space, top_n=1,\n",
    "    local_optimizer=hyperopt_optimizer\n",
    ")[0]\n",
    "\n",
    "print(report.sort_metric, report)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000001665414 {'trial': {'trial_id': '971ef4a5-71a9-5bf2-b2a4-f0f1acd02b78', 'params': {'a': 1, 'b': 1.2905089873156781e-05}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000001665414, 'params': {'a': 1, 'b': 1.2905089873156781e-05}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000001665414, 'log_time': datetime.datetime(2021, 10, 6, 23, 31, 43, 784128)}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also provide only random expressions in space, and use in the same way so it looks like a common case similar to the examples "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1,\n",
    "    local_optimizer=optuna_optimizer\n",
    ")[0]\n",
    "\n",
    "print(report.sort_metric, report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.04085386621249434 {'trial': {'trial_id': '45179c01-7358-5546-8f41-d7c6f120523f', 'params': {'a': 0.01604913454189394, 'b': 0.20148521408021614}, 'metadata': {}, 'keys': []}, 'metric': 0.04085386621249434, 'params': {'a': 0.01604913454189394, 'b': 0.20148521408021614}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.04085386621249434, 'log_time': datetime.datetime(2021, 10, 6, 23, 34, 47, 379901)}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Factory Method\n",
    "\n",
    "In the above example, if we don't set `local_optimizer`, then the default level 2 optimizer will be used which can't handle a configuration with random expressions.\n",
    "\n",
    "So we have a nice way to make certain optimizer the default one."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from tune import NonIterativeObjectiveLocalOptimizer, TUNE_OBJECT_FACTORY\n",
    "\n",
    "def to_optimizer(obj):\n",
    "    if isinstance(obj, NonIterativeObjectiveLocalOptimizer):\n",
    "        return obj\n",
    "    if obj is None or \"hyperopt\"==obj:\n",
    "        return HyperoptLocalOptimizer(max_iter=200, seed=0)\n",
    "    if \"optuna\" == obj:\n",
    "        return OptunaLocalOptimizer(max_iter=200)\n",
    "    raise NotImplementedError\n",
    "\n",
    "TUNE_OBJECT_FACTORY.set_noniterative_local_optimizer_converter(to_optimizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now Hyperopt becomes the default level 2 optimizer, and you can switch to Optuna by specifying a string parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1\n",
    ")[0]  # using hyperopt\n",
    "\n",
    "print(report.sort_metric, report)\n",
    "\n",
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1,\n",
    "    local_optimizer=\"optuna\"\n",
    ")[0]  # using hyperopt\n",
    "\n",
    "print(report.sort_metric, report)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n",
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.02788888054657708 {'trial': {'trial_id': '45179c01-7358-5546-8f41-d7c6f120523f', 'params': {'a': -0.13745463941867586, 'b': -0.09484251498594332}, 'metadata': {}, 'keys': []}, 'metric': 0.02788888054657708, 'params': {'a': -0.13745463941867586, 'b': -0.09484251498594332}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.02788888054657708, 'log_time': datetime.datetime(2021, 10, 6, 23, 35, 19, 961138)}\n",
      "0.010490219126635992 {'trial': {'trial_id': '45179c01-7358-5546-8f41-d7c6f120523f', 'params': {'a': 0.06699961867542388, 'b': -0.07746786575079878}, 'metadata': {}, 'keys': []}, 'metric': 0.010490219126635992, 'params': {'a': 0.06699961867542388, 'b': -0.07746786575079878}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.010490219126635992, 'log_time': datetime.datetime(2021, 10, 6, 23, 35, 21, 593974)}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}