{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd04cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Non-Iterative Optimizers\n",
    "\n",
    "AKA Level 2 optimizers, are unified 3rd party solutions for random expressions. Look at this space:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': <tune.concepts.space.parameters.Rand at 0x7f69b01dbf10>},\n",
       " {'a': 2, 'b': <tune.concepts.space.parameters.Rand at 0x7f696d9db390>}]"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from tune import Space, Grid, Rand\n",
    "\n",
    "space = Space(a=Grid(1,2), b=Rand(0,1))\n",
    "list(space)"
   ]
  },
  {
   "source": [
    "`Grid` is for level 1 optimization, all level 1 parameters will be converted to static values before execution. And level 2 parameters will be optimized during runtime using level 2 optimizers. So for the above example, if we have a Spark cluster and Hyperopt, then we can use Hyperot to search for the best `b` on each of the 2 configurations. And the 2 jobs are parallelized by Spark."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune import noniterative_objective, Trial\n",
    "\n",
    "@noniterative_objective\n",
    "def objective(a ,b) -> float:\n",
    "    return a**2 + b**2\n",
    "\n",
    "trial = Trial(\"dummy\", params=list(space)[0])"
   ]
  },
  {
   "source": [
    "\n",
    "## Use Directly\n",
    "\n",
    "Notice normally you don't use them directly, instead you should use them through top level APIs. This is just to demo how they work.\n",
    "\n",
    "### Hyperopt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000001665414 {'trial': {'trial_id': 'dummy', 'params': {'b': 1.2905089873156781e-05, 'a': 1}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000001665414, 'params': {'b': 1.2905089873156781e-05, 'a': 1}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000001665414, 'log_time': '2021-05-26 20:55:31.619532'}\n"
     ]
    }
   ],
   "source": [
    "from tune_hyperopt import HyperoptLocalOptimizer\n",
    "\n",
    "hyperopt_optimizer = HyperoptLocalOptimizer(max_iter=200, seed=0)\n",
    "report = hyperopt_optimizer.run(objective, trial)\n",
    "\n",
    "print(report.sort_metric, report.jsondict)\n"
   ]
  },
  {
   "source": [
    "### Optuna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000000272453 {'trial': {'trial_id': 'dummy', 'params': {'b': 5.21970292443935e-06, 'a': 1}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000000272453, 'params': {'b': 5.21970292443935e-06, 'a': 1}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000000272453, 'log_time': '2021-05-26 20:55:32.615325'}\n"
     ]
    }
   ],
   "source": [
    "from tune_optuna import OptunaLocalOptimizer\n",
    "import optuna\n",
    "\n",
    "optuna.logging.disable_default_handler()\n",
    "\n",
    "optuna_optimizer = OptunaLocalOptimizer(max_iter=200)\n",
    "report = optuna_optimizer.run(objective, trial)\n",
    "\n",
    "print(report.sort_metric, report.jsondict)"
   ]
  },
  {
   "source": [
    "As you see, we have unified the interfaces for using these frameworks. In addition, we also unified the semantic of the random expressions, so the random sampling behavior will be highly consistent on different 3rd party solutions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Use Top Level API\n",
    "\n",
    "In the following example, we directly use the entire `space` where you can mix grid search, random search and Bayesian Optimization."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n",
      "1.0000000001665414 {'trial': {'trial_id': 'f148c660-8242-5b04-b236-948f04bdc278', 'params': {'b': 1.2905089873156781e-05, 'a': 1}, 'metadata': {}, 'keys': []}, 'metric': 1.0000000001665414, 'params': {'b': 1.2905089873156781e-05, 'a': 1}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 1.0000000001665414, 'log_time': '2021-05-26 20:55:33.332008'}\n"
     ]
    }
   ],
   "source": [
    "from tune import suggest_for_noniterative_objective\n",
    "\n",
    "report = suggest_for_noniterative_objective(\n",
    "    objective, space, top_n=1,\n",
    "    local_optimizer=hyperopt_optimizer\n",
    ")[0]\n",
    "\n",
    "print(report.sort_metric, report.jsondict)\n"
   ]
  },
  {
   "source": [
    "You can also provide only random expressions in space, and use in the same way so it looks like a common case similar to the examples "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n",
      "0.06521508864728201 {'trial': {'trial_id': '15893b38-503d-55d7-8028-4938a180d7aa', 'params': {'a': 0.19166075408974875, 'b': -0.16876387050856256}, 'metadata': {}, 'keys': []}, 'metric': 0.06521508864728201, 'params': {'a': 0.19166075408974875, 'b': -0.16876387050856256}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.06521508864728201, 'log_time': '2021-05-26 20:56:12.362704'}\n"
     ]
    }
   ],
   "source": [
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1,\n",
    "    local_optimizer=optuna_optimizer\n",
    ")[0]\n",
    "\n",
    "print(report.sort_metric, report.jsondict)"
   ]
  },
  {
   "source": [
    "## Factory Method\n",
    "\n",
    "In the above example, if we don't set `local_optimizer`, then the default level 2 optimizer will be used which can't handle a configuration with random expressions.\n",
    "\n",
    "So we have a nice way to make certain optimizer the default one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune import NonIterativeObjectiveLocalOptimizer, TUNE_OBJECT_FACTORY\n",
    "\n",
    "def to_optimizer(obj):\n",
    "    if isinstance(obj, NonIterativeObjectiveLocalOptimizer):\n",
    "        return obj\n",
    "    if obj is None or \"hyperopt\"==obj:\n",
    "        return HyperoptLocalOptimizer(max_iter=200, seed=0)\n",
    "    if \"optuna\" == obj:\n",
    "        return OptunaLocalOptimizer(max_iter=200)\n",
    "    raise NotImplementedError\n",
    "\n",
    "TUNE_OBJECT_FACTORY.set_noniterative_local_optimizer_converter(to_optimizer)"
   ]
  },
  {
   "source": [
    "Now Hyperopt becomes the default level 2 optimizer, and you can switch to Optuna by specifying a string parameter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n",
      "NativeExecutionEngine doesn't respect num_partitions ROWCOUNT\n",
      "0.02788888054657708 {'trial': {'trial_id': '15893b38-503d-55d7-8028-4938a180d7aa', 'params': {'a': -0.13745463941867586, 'b': -0.09484251498594332}, 'metadata': {}, 'keys': []}, 'metric': 0.02788888054657708, 'params': {'a': -0.13745463941867586, 'b': -0.09484251498594332}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.02788888054657708, 'log_time': '2021-05-26 21:04:34.684192'}\n",
      "0.0010892636221917031 {'trial': {'trial_id': '15893b38-503d-55d7-8028-4938a180d7aa', 'params': {'a': -0.0209959472430835, 'b': -0.025464363757167735}, 'metadata': {}, 'keys': []}, 'metric': 0.0010892636221917031, 'params': {'a': -0.0209959472430835, 'b': -0.025464363757167735}, 'metadata': {}, 'cost': 1.0, 'rung': 0, 'sort_metric': 0.0010892636221917031, 'log_time': '2021-05-26 21:04:36.001186'}\n"
     ]
    }
   ],
   "source": [
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1\n",
    ")[0]  # using hyperopt\n",
    "\n",
    "print(report.sort_metric, report.jsondict)\n",
    "\n",
    "report = suggest_for_noniterative_objective(\n",
    "    objective, Space(a=Rand(-1,1), b=Rand(-100,100)), top_n=1,\n",
    "    local_optimizer=\"optuna\"\n",
    ")[0]  # using hyperopt\n",
    "\n",
    "print(report.sort_metric, report.jsondict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}